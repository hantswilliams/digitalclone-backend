{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUa7Evm7DKCY",
        "outputId": "d972b57c-7ad0-49de-de36-4511f132cfe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tts\n",
            "  Downloading TTS-0.9.0-cp38-cp38-manylinux1_x86_64.whl (566 kB)\n",
            "\u001b[K     |████████████████████████████████| 566 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from tts) (1.7.3)\n",
            "Collecting gruut[de]==2.2.3\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting librosa==0.8.0\n",
            "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
            "\u001b[K     |████████████████████████████████| 183 kB 72.4 MB/s \n",
            "\u001b[?25hCollecting trainer\n",
            "  Downloading trainer-0.0.18-py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from tts) (3.2.2)\n",
            "Collecting mecab-python3==1.0.5\n",
            "  Downloading mecab_python3-1.0.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (577 kB)\n",
            "\u001b[K     |████████████████████████████████| 577 kB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tts) (4.64.1)\n",
            "Collecting inflect==5.6.0\n",
            "  Downloading inflect-5.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.8/dist-packages (from tts) (0.42.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (from tts) (0.13.0+cu116)\n",
            "Collecting pysbd\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 9.5 MB/s \n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 77.4 MB/s \n",
            "\u001b[?25hCollecting cython==0.29.28\n",
            "  Downloading Cython-0.29.28-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: soundfile in /usr/local/lib/python3.8/dist-packages (from tts) (0.11.0)\n",
            "Collecting coqpit>=0.0.16\n",
            "  Downloading coqpit-0.0.16-py3-none-any.whl (13 kB)\n",
            "Collecting pypinyin\n",
            "  Downloading pypinyin-0.47.1-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from tts) (1.13.0+cu116)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.8/dist-packages (from tts) (1.1.4)\n",
            "Collecting jamo\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: fsspec>=2021.04.0 in /usr/local/lib/python3.8/dist-packages (from tts) (2022.11.0)\n",
            "Collecting g2pkk>=0.1.1\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from tts) (1.3.5)\n",
            "Requirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.8/dist-packages (from tts) (1.21.6)\n",
            "Collecting umap-learn==0.5.1\n",
            "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 13.1 MB/s \n",
            "\u001b[?25hCollecting unidic-lite==1.0.8\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting numba==0.55.1\n",
            "  Downloading numba-0.55.1-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 64.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from tts) (6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from tts) (3.7)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->tts) (2.11.0)\n",
            "Collecting dateparser~=1.1.0\n",
            "  Downloading dateparser-1.1.4-py2.py3-none-any.whl (292 kB)\n",
            "\u001b[K     |████████████████████████████████| 292 kB 74.1 MB/s \n",
            "\u001b[?25hCollecting gruut-ipa<1.0,>=0.12.0\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 16.3 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_en~=2.0.0\n",
            "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.2 MB 58.7 MB/s \n",
            "\u001b[?25hCollecting jsonlines~=1.2.0\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->tts) (2.8.8)\n",
            "Collecting num2words<1.0.0,>=0.5.10\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 76.7 MB/s \n",
            "\u001b[?25hCollecting python-crfsuite~=0.9.7\n",
            "  Downloading python_crfsuite-0.9.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 50.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib_resources in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->tts) (5.10.0)\n",
            "Collecting gruut_lang_de~=2.0.0\n",
            "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.1 MB 30.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->tts) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->tts) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->tts) (1.2.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->tts) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->tts) (0.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->tts) (1.6.0)\n",
            "Collecting llvmlite<0.39,>=0.38.0rc1\n",
            "  Downloading llvmlite-0.38.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 7.1 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba==0.55.1->tts) (57.4.0)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 76.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.8/dist-packages (from Babel<3.0.0,>=2.8.0->gruut[de]==2.2.3->tts) (2022.6)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from dateparser~=1.1.0->gruut[de]==2.2.3->tts) (2.8.2)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.8/dist-packages (from dateparser~=1.1.0->gruut[de]==2.2.3->tts) (2022.6.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.8/dist-packages (from dateparser~=1.1.0->gruut[de]==2.2.3->tts) (1.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from jsonlines~=1.2.0->gruut[de]==2.2.3->tts) (1.15.0)\n",
            "Collecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa==0.8.0->tts) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa==0.8.0->tts) (21.3)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa==0.8.0->tts) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->pooch>=1.0->librosa==0.8.0->tts) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->tts) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->tts) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->tts) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->tts) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0->tts) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile->tts) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile->tts) (2.21)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->tts) (4.4.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from flask->tts) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from flask->tts) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from flask->tts) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from flask->tts) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->flask->tts) (2.0.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib_resources->gruut[de]==2.2.3->tts) (3.11.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->tts) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->tts) (1.4.4)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 78.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from trainer->tts) (5.4.8)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from trainer->tts) (3.19.6)\n",
            "Building wheels for collected packages: gruut, librosa, umap-learn, unidic-lite, gruut-ipa, gruut-lang-de, gruut-lang-en, docopt, pynndescent\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75819 sha256=c7dad10e114db4b2008b94cb91fc851159766fdd32b88f8736e161890bc9c4c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/77/15/4d57c0e698b2340faa0ca0b1638ffce2683aacc4e41d5123d8\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201396 sha256=664cacef38724b679c8117d3f18c1664d4a48ef1f322dfec1c95010d7f2121ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/5a/92/d52f6f8560ff05a2525e6030a1903412df876714241fb76802\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76566 sha256=96bd345b73affdb240dda07fc1472be29c9d7a2b9d841c64e4249f1b277d62b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/85/b7/b4b7040e49367b6d1505d7e8fb57e3e79b22fa6ac26f72520b\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658837 sha256=6e4c356d2d56582735f0955d65abf44011a13a5233ad5efd475d532459f24c6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/dd/8f/e21fc192dcd38ae31e1185ce4e66e12df4e811e3d469866e15\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104895 sha256=2d196d114583e1e7bc581082fc2eb7c91b114a641f4301058fb32065b703d1ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/ef/27/f88344c08d8cca457a5316a39b099505e68a9f2a0547e0c5e7\n",
            "  Building wheel for gruut-lang-de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498199 sha256=6a7c4bf2958486474aff1aa3824034626edf6ae92b6aceb417a892ea997cae41\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/e1/60/d80ef587c3dd944644291065719d35ff92747b8e65135b2aa5\n",
            "  Building wheel for gruut-lang-en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297198 sha256=d7952781872eeebd704c9bfde6ab6d7113abaec308e094f2b6db31de70ab6b0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f7/60/ddc598856abe98015bfefa228160da28a0d5d0ba39b4c7ddf4\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=b1f4e9b8ce31cd81a57e3539c14b27f0f976e24ead89fe9387e080dcb2cd1b4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55513 sha256=70dd74082e0fb9c579e7e821eb1101563860db1f3b8cc8ed4a604001eccf1121\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/63/3a/29954bca1a27ba100ed8c27973a78cb71b43dc67aed62e80c3\n",
            "Successfully built gruut librosa umap-learn unidic-lite gruut-ipa gruut-lang-de gruut-lang-en docopt pynndescent\n",
            "Installing collected packages: llvmlite, docopt, python-crfsuite, numba, num2words, jsonlines, gruut-lang-en, gruut-ipa, dateparser, tensorboardX, pynndescent, jamo, gruut-lang-de, gruut, coqpit, unidic-lite, umap-learn, trainer, pysbd, pypinyin, mecab-python3, librosa, inflect, g2pkk, cython, anyascii, tts\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "  Attempting uninstall: inflect\n",
            "    Found existing installation: inflect 2.1.0\n",
            "    Uninstalling inflect-2.1.0:\n",
            "      Successfully uninstalled inflect-2.1.0\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 0.29.32\n",
            "    Uninstalling Cython-0.29.32:\n",
            "      Successfully uninstalled Cython-0.29.32\n",
            "Successfully installed anyascii-0.3.1 coqpit-0.0.16 cython-0.29.28 dateparser-1.1.4 docopt-0.6.2 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut-lang-de-2.0.0 gruut-lang-en-2.0.0 inflect-5.6.0 jamo-0.4.1 jsonlines-1.2.0 librosa-0.8.0 llvmlite-0.38.1 mecab-python3-1.0.5 num2words-0.5.12 numba-0.55.1 pynndescent-0.5.8 pypinyin-0.47.1 pysbd-0.3.4 python-crfsuite-0.9.8 tensorboardX-2.5.1 trainer-0.0.18 tts-0.9.0 umap-learn-0.5.1 unidic-lite-1.0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install tts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tts"
      ],
      "metadata": {
        "id": "KRBYjNFhDMBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
        "from TTS.config.shared_configs import BaseAudioConfig\n",
        "from TTS.utils.audio import AudioProcessor\n",
        "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
        "from TTS.tts.models.vits import Vits\n",
        "from TTS.tts.configs.vits_config import VitsConfig\n",
        "from trainer import Trainer, TrainerArgs\n",
        "from TTS.tts.datasets import load_tts_samples"
      ],
      "metadata": {
        "id": "nTJ3CTwGDkFg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "fgGJ_V2aKXk9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hantswilliams/digitalclone-backend.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pyldHtkDpAD",
        "outputId": "c6ed10f2-fc7f-4ada-e230-5301fc51361e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'digitalclone-backend'...\n",
            "remote: Enumerating objects: 345, done.\u001b[K\n",
            "remote: Counting objects: 100% (204/204), done.\u001b[K\n",
            "remote: Compressing objects: 100% (191/191), done.\u001b[K\n",
            "remote: Total 345 (delta 82), reused 124 (delta 3), pack-reused 141\u001b[K\n",
            "Receiving objects: 100% (345/345), 41.96 MiB | 45.42 MiB/s, done.\n",
            "Resolving deltas: 100% (131/131), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd digitalclone-backend/ && git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdU7Q4npDvYW",
        "outputId": "c688d891-52ce-4e0d-c264-22bba1170243"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/digitalclone-backend/aws_jobs_voiceclone/tts_tests/testdatasets/audiofiles/\"\n",
        "output_path = \"/content/trainoutput\""
      ],
      "metadata": {
        "id": "_TWFBSCTIQ_3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of files in audiofiles/wavs\n",
        "audiofiles = os.listdir(dataset_path + \"/wavs\")\n",
        "print('audiofiles...:', audiofiles)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q77_fwOKQuB",
        "outputId": "c8f7aa45-1b20-48a2-a7cb-823a3a8b1d88"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audiofiles...: ['list1-q4_1664299449480.wav', 'list1-q2_1664299434662.wav', 'list1-q8_1664299479477.wav', 'list1-q1_1664299399500.wav', 'list1-q5_1664299457270.wav', 'list1-q7_1664299472544.wav', 'list1-q10_1664299494437.wav', 'list1-q6_1664299464874.wav', 'list1-q3_1664299442218.wav', 'list1-q9_1664299487431.wav']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through each file in audiofiles/wavs and convert to 22050\n",
        "for file in audiofiles:\n",
        "    # get file name\n",
        "    filename = file.split(\".\")[0]\n",
        "    # get file extension\n",
        "    fileext = file.split(\".\")[1]\n",
        "    # create command to convert file to 22050\n",
        "    command = \"ffmpeg -i \" + dataset_path + \"/wavs/\" + file + \" -ar 16000 -ac 1 \" + dataset_path + \"/wavs/\" + filename + \"_mod.\" + fileext + \" -y\"\n",
        "    # run command\n",
        "    os.system(command)\n",
        "    # print\n",
        "    print(\"converted \" + file + \" to 16000\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jiy1ksGiKbwe",
        "outputId": "9033ae50-26ea-4eb6-a7f5-af1af87fafad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "converted list1-q4_1664299449480.wav to 16000\n",
            "converted list1-q2_1664299434662.wav to 16000\n",
            "converted list1-q8_1664299479477.wav to 16000\n",
            "converted list1-q1_1664299399500.wav to 16000\n",
            "converted list1-q5_1664299457270.wav to 16000\n",
            "converted list1-q7_1664299472544.wav to 16000\n",
            "converted list1-q10_1664299494437.wav to 16000\n",
            "converted list1-q6_1664299464874.wav to 16000\n",
            "converted list1-q3_1664299442218.wav to 16000\n",
            "converted list1-q9_1664299487431.wav to 16000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tpower = 1.3\n",
        "tpreemphasis = 0.98\n",
        "tdb = 20\n",
        "######################\n",
        "\n",
        "\n",
        "dataset_config = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\", meta_file_train='metaData_list1_1664477626975..txt', path=os.path.join(output_path, dataset_path)\n",
        ")\n",
        "\n",
        "audio_config = BaseAudioConfig(\n",
        "    sample_rate=22050, \n",
        "    win_length=1024, \n",
        "    hop_length=256, \n",
        "    num_mels=80, \n",
        "    mel_fmin=0, \n",
        "    mel_fmax=None, \n",
        "    power=tpower,\n",
        "    preemphasis=tpreemphasis,\n",
        "    ref_level_db=tdb\n",
        ")\n",
        "\n",
        "config = VitsConfig(\n",
        "    audio=audio_config,\n",
        "    run_name=\"vits_ljspeech\",\n",
        "    batch_size=32,\n",
        "    eval_batch_size=16,\n",
        "    batch_group_size=5,\n",
        "    num_loader_workers=8,\n",
        "    num_eval_loader_workers=4,\n",
        "    run_eval=True,\n",
        "    test_delay_epochs=-1,\n",
        "    epochs=100,\n",
        "    text_cleaner=\"english_cleaners\",\n",
        "    use_phonemes=True,\n",
        "    phoneme_language=\"en-us\",\n",
        "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
        "    compute_input_seq_cache=True,\n",
        "    print_step=25,\n",
        "    print_eval=True,\n",
        "    mixed_precision=True,\n",
        "    output_path=output_path,\n",
        "    datasets=[dataset_config],\n",
        "    cudnn_benchmark=False\n",
        ")"
      ],
      "metadata": {
        "id": "Q78X08hUKiRB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples, eval_samples = load_tts_samples(\n",
        "    dataset_config,\n",
        "    eval_split=True,\n",
        "    eval_split_max_size=config.eval_split_max_size,\n",
        "    # eval_split_size=config.eval_split_size\n",
        "    eval_split_size=0.1\n",
        ")\n",
        "\n",
        "ap = AudioProcessor.init_from_config(config)\n",
        "tokenizer, config = TTSTokenizer.init_from_config(config)\n",
        "model = Vits(config, ap, tokenizer, speaker_manager=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsAHcms4Kmpi",
        "outputId": "64d7f36b-9671-412b-e614-47b06cc816b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Found 10 files in /content/digitalclone-backend/aws_jobs_voiceclone/tts_tests/testdatasets/audiofiles\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.3\n",
            " | > preemphasis:0.98\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:45\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
        ")\n",
        "\n",
        "trainer.fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COMBB1P1K8fx",
        "outputId": "a5c78a0e-9d73-4ab9-b1dc-7fb933e3dc16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " > Training Environment:\n",
            " | > Current device: 0\n",
            " | > Num. of GPUs: 1\n",
            " | > Num. of CPUs: 2\n",
            " | > Num. of Torch Threads: 1\n",
            " | > Torch seed: 54321\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            "\n",
            " > Model has 83059180 parameters\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] Pre-computing phonemes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 5/9 [00:00<00:00, 15.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<BLNK>', 'ə', '<BLNK>', ' ', '<BLNK>', 'l', '<BLNK>', 'ɑ', '<BLNK>', 'ɹ', '<BLNK>', 'd', '<BLNK>', '͡', '<BLNK>', 'ʒ', '<BLNK>', ' ', '<BLNK>', 's', '<BLNK>', 'a', '<BLNK>', 'ɪ', '<BLNK>', 'z', '<BLNK>', ' ', '<BLNK>', 'ɪ', '<BLNK>', 'n', '<BLNK>', ' ', '<BLNK>', 's', '<BLNK>', 't', '<BLNK>', 'ɑ', '<BLNK>', 'k', '<BLNK>', 'ɪ', '<BLNK>', 'ŋ', '<BLNK>', 'z', '<BLNK>', ' ', '<BLNK>', 'ɪ', '<BLNK>', 'z', '<BLNK>', ' ', '<BLNK>', 'h', '<BLNK>', 'ɑ', '<BLNK>', 'ɹ', '<BLNK>', 'd', '<BLNK>', ' ', '<BLNK>', 't', '<BLNK>', 'ə', '<BLNK>', ' ', '<BLNK>', 's', '<BLNK>', 'ɛ', '<BLNK>', 'l', '<BLNK>']\n",
            " [!] Character '͡' not found in the vocabulary. Discarding it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 15.80it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:39:36) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:632: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:801.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "\n",
            "\u001b[1m   --> STEP: 0/1 -- GLOBAL_STEP: 0\u001b[0m\n",
            "     | > loss_disc: 5.91686  (5.91686)\n",
            "     | > loss_disc_real_0: 0.98846  (0.98846)\n",
            "     | > loss_disc_real_1: 0.96979  (0.96979)\n",
            "     | > loss_disc_real_2: 0.99398  (0.99398)\n",
            "     | > loss_disc_real_3: 0.96346  (0.96346)\n",
            "     | > loss_disc_real_4: 1.00671  (1.00671)\n",
            "     | > loss_disc_real_5: 0.99382  (0.99382)\n",
            "     | > loss_0: 5.91686  (5.91686)\n",
            "     | > grad_norm_0: 0.00000  (0.00000)\n",
            "     | > loss_gen: 5.91648  (5.91648)\n",
            "     | > loss_kl: 173.78734  (173.78734)\n",
            "     | > loss_feat: 0.21646  (0.21646)\n",
            "     | > loss_mel: 88.47365  (88.47365)\n",
            "     | > loss_duration: 1.62500  (1.62500)\n",
            "     | > amp_scaler: 32768.00000  (32768.00000)\n",
            "     | > loss_1: 270.01892  (270.01892)\n",
            "     | > grad_norm_1: 0.00000  (0.00000)\n",
            "     | > current_lr_0: 0.00020 \n",
            "     | > current_lr_1: 0.00020 \n",
            "     | > step_time: 6.74900  (6.74905)\n",
            "     | > loader_time: 3.57800  (3.57803)\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 5.91671  (5.91671)\n",
            "     | > loss_disc_real_0: 0.98839  (0.98839)\n",
            "     | > loss_disc_real_1: 0.96977  (0.96977)\n",
            "     | > loss_disc_real_2: 0.99397  (0.99397)\n",
            "     | > loss_disc_real_3: 0.96351  (0.96351)\n",
            "     | > loss_disc_real_4: 1.00661  (1.00661)\n",
            "     | > loss_disc_real_5: 0.99381  (0.99381)\n",
            "     | > loss_0: 5.91671  (5.91671)\n",
            "     | > loss_gen: 5.91646  (5.91646)\n",
            "     | > loss_kl: 183.78004  (183.78004)\n",
            "     | > loss_feat: 0.31435  (0.31435)\n",
            "     | > loss_mel: 87.97678  (87.97678)\n",
            "     | > loss_duration: 2.26444  (2.26444)\n",
            "     | > loss_1: 280.25208  (280.25208)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/TTS/tts/models/vits.py:1454: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3277.)\n",
            "  test_figures[\"{}-alignment\".format(idx)] = plot_alignment(alignment.T, output_fig=False)\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.21235 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc: 5.91671 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_0: 0.98839 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_1: 0.96977 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_2: 0.99397 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_3: 0.96351 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_4: 1.00661 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_5: 0.99381 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_0: 5.91671 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_gen: 5.91646 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_kl: 183.78004 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_feat: 0.31435 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_mel: 87.97678 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_duration: 2.26444 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_1: 280.25208 \u001b[0m(+0.00000)\n",
            "\n",
            " > BEST MODEL : /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000/best_model_1.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 1/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:39:53) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 5.91739  (5.91739)\n",
            "     | > loss_disc_real_0: 0.98849  (0.98849)\n",
            "     | > loss_disc_real_1: 0.96964  (0.96964)\n",
            "     | > loss_disc_real_2: 0.99427  (0.99427)\n",
            "     | > loss_disc_real_3: 0.96322  (0.96322)\n",
            "     | > loss_disc_real_4: 1.00693  (1.00693)\n",
            "     | > loss_disc_real_5: 0.99420  (0.99420)\n",
            "     | > loss_0: 5.91739  (5.91739)\n",
            "     | > loss_gen: 5.91646  (5.91646)\n",
            "     | > loss_kl: 179.53963  (179.53963)\n",
            "     | > loss_feat: 0.35630  (0.35630)\n",
            "     | > loss_mel: 106.86307  (106.86307)\n",
            "     | > loss_duration: 1.89760  (1.89760)\n",
            "     | > loss_1: 294.57306  (294.57306)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17246 \u001b[0m(-0.03989)\n",
            "     | > avg_loss_disc:\u001b[91m 5.91739 \u001b[0m(+0.00068)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.98849 \u001b[0m(+0.00010)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.96964 \u001b[0m(-0.00013)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.99427 \u001b[0m(+0.00030)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.96322 \u001b[0m(-0.00029)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 1.00693 \u001b[0m(+0.00032)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.99420 \u001b[0m(+0.00039)\n",
            "     | > avg_loss_0:\u001b[91m 5.91739 \u001b[0m(+0.00068)\n",
            "     | > avg_loss_gen:\u001b[91m 5.91646 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_kl:\u001b[92m 179.53963 \u001b[0m(-4.24042)\n",
            "     | > avg_loss_feat:\u001b[91m 0.35630 \u001b[0m(+0.04195)\n",
            "     | > avg_loss_mel:\u001b[91m 106.86307 \u001b[0m(+18.88628)\n",
            "     | > avg_loss_duration:\u001b[92m 1.89760 \u001b[0m(-0.36684)\n",
            "     | > avg_loss_1:\u001b[91m 294.57306 \u001b[0m(+14.32098)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 2/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:39:57) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 4.58800  (4.58800)\n",
            "     | > loss_disc_real_0: 0.63843  (0.63843)\n",
            "     | > loss_disc_real_1: 0.69293  (0.69293)\n",
            "     | > loss_disc_real_2: 0.79443  (0.79443)\n",
            "     | > loss_disc_real_3: 0.72775  (0.72775)\n",
            "     | > loss_disc_real_4: 0.81948  (0.81948)\n",
            "     | > loss_disc_real_5: 0.78930  (0.78930)\n",
            "     | > loss_0: 4.58800  (4.58800)\n",
            "     | > loss_gen: 4.46952  (4.46952)\n",
            "     | > loss_kl: 177.95290  (177.95290)\n",
            "     | > loss_feat: 0.33931  (0.33931)\n",
            "     | > loss_mel: 102.99659  (102.99659)\n",
            "     | > loss_duration: 2.26493  (2.26493)\n",
            "     | > loss_1: 288.02322  (288.02322)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.16608 \u001b[0m(-0.00638)\n",
            "     | > avg_loss_disc:\u001b[92m 4.58800 \u001b[0m(-1.32939)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.63843 \u001b[0m(-0.35005)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.69293 \u001b[0m(-0.27671)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.79443 \u001b[0m(-0.19984)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.72775 \u001b[0m(-0.23547)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.81948 \u001b[0m(-0.18745)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.78930 \u001b[0m(-0.20491)\n",
            "     | > avg_loss_0:\u001b[92m 4.58800 \u001b[0m(-1.32939)\n",
            "     | > avg_loss_gen:\u001b[92m 4.46952 \u001b[0m(-1.44694)\n",
            "     | > avg_loss_kl:\u001b[92m 177.95290 \u001b[0m(-1.58673)\n",
            "     | > avg_loss_feat:\u001b[92m 0.33931 \u001b[0m(-0.01699)\n",
            "     | > avg_loss_mel:\u001b[92m 102.99659 \u001b[0m(-3.86648)\n",
            "     | > avg_loss_duration:\u001b[91m 2.26493 \u001b[0m(+0.36733)\n",
            "     | > avg_loss_1:\u001b[92m 288.02322 \u001b[0m(-6.54984)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 3/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:40:02) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.46558  (3.46558)\n",
            "     | > loss_disc_real_0: 0.37996  (0.37996)\n",
            "     | > loss_disc_real_1: 0.35167  (0.35167)\n",
            "     | > loss_disc_real_2: 0.53731  (0.53731)\n",
            "     | > loss_disc_real_3: 0.42922  (0.42922)\n",
            "     | > loss_disc_real_4: 0.58028  (0.58028)\n",
            "     | > loss_disc_real_5: 0.53878  (0.53878)\n",
            "     | > loss_0: 3.46558  (3.46558)\n",
            "     | > loss_gen: 2.83508  (2.83508)\n",
            "     | > loss_kl: 179.61665  (179.61665)\n",
            "     | > loss_feat: 0.41266  (0.41266)\n",
            "     | > loss_mel: 98.41933  (98.41933)\n",
            "     | > loss_duration: 2.09724  (2.09724)\n",
            "     | > loss_1: 283.38095  (283.38095)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.16059 \u001b[0m(-0.00549)\n",
            "     | > avg_loss_disc:\u001b[92m 3.46558 \u001b[0m(-1.12242)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.37996 \u001b[0m(-0.25847)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.35167 \u001b[0m(-0.34126)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.53731 \u001b[0m(-0.25712)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.42922 \u001b[0m(-0.29853)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.58028 \u001b[0m(-0.23920)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.53878 \u001b[0m(-0.25052)\n",
            "     | > avg_loss_0:\u001b[92m 3.46558 \u001b[0m(-1.12242)\n",
            "     | > avg_loss_gen:\u001b[92m 2.83508 \u001b[0m(-1.63444)\n",
            "     | > avg_loss_kl:\u001b[91m 179.61665 \u001b[0m(+1.66376)\n",
            "     | > avg_loss_feat:\u001b[91m 0.41266 \u001b[0m(+0.07335)\n",
            "     | > avg_loss_mel:\u001b[92m 98.41933 \u001b[0m(-4.57726)\n",
            "     | > avg_loss_duration:\u001b[92m 2.09724 \u001b[0m(-0.16769)\n",
            "     | > avg_loss_1:\u001b[92m 283.38095 \u001b[0m(-4.64227)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 4/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:40:06) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.37783  (3.37783)\n",
            "     | > loss_disc_real_0: 0.19323  (0.19323)\n",
            "     | > loss_disc_real_1: 0.04491  (0.04491)\n",
            "     | > loss_disc_real_2: 0.19090  (0.19090)\n",
            "     | > loss_disc_real_3: 0.11042  (0.11042)\n",
            "     | > loss_disc_real_4: 0.26779  (0.26779)\n",
            "     | > loss_disc_real_5: 0.22320  (0.22320)\n",
            "     | > loss_0: 3.37783  (3.37783)\n",
            "     | > loss_gen: 1.06278  (1.06278)\n",
            "     | > loss_kl: 182.58072  (182.58072)\n",
            "     | > loss_feat: 0.58397  (0.58397)\n",
            "     | > loss_mel: 72.61586  (72.61586)\n",
            "     | > loss_duration: 2.32645  (2.32645)\n",
            "     | > loss_1: 259.16977  (259.16977)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.16925 \u001b[0m(+0.00866)\n",
            "     | > avg_loss_disc:\u001b[92m 3.37783 \u001b[0m(-0.08775)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.19323 \u001b[0m(-0.18673)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.04491 \u001b[0m(-0.30675)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.19090 \u001b[0m(-0.34641)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.11042 \u001b[0m(-0.31880)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.26779 \u001b[0m(-0.31249)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.22320 \u001b[0m(-0.31558)\n",
            "     | > avg_loss_0:\u001b[92m 3.37783 \u001b[0m(-0.08775)\n",
            "     | > avg_loss_gen:\u001b[92m 1.06278 \u001b[0m(-1.77230)\n",
            "     | > avg_loss_kl:\u001b[91m 182.58072 \u001b[0m(+2.96407)\n",
            "     | > avg_loss_feat:\u001b[91m 0.58397 \u001b[0m(+0.17131)\n",
            "     | > avg_loss_mel:\u001b[92m 72.61586 \u001b[0m(-25.80347)\n",
            "     | > avg_loss_duration:\u001b[91m 2.32645 \u001b[0m(+0.22921)\n",
            "     | > avg_loss_1:\u001b[92m 259.16977 \u001b[0m(-24.21118)\n",
            "\n",
            " > BEST MODEL : /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000/best_model_5.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 5/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:40:16) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.56243  (3.56243)\n",
            "     | > loss_disc_real_0: 0.12282  (0.12282)\n",
            "     | > loss_disc_real_1: 0.15576  (0.15576)\n",
            "     | > loss_disc_real_2: 0.09164  (0.09164)\n",
            "     | > loss_disc_real_3: 0.15760  (0.15760)\n",
            "     | > loss_disc_real_4: 0.08991  (0.08991)\n",
            "     | > loss_disc_real_5: 0.13172  (0.13172)\n",
            "     | > loss_0: 3.56243  (3.56243)\n",
            "     | > loss_gen: 0.75806  (0.75806)\n",
            "     | > loss_kl: 179.26276  (179.26276)\n",
            "     | > loss_feat: 0.11959  (0.11959)\n",
            "     | > loss_mel: 72.24747  (72.24747)\n",
            "     | > loss_duration: 2.35861  (2.35861)\n",
            "     | > loss_1: 254.74648  (254.74648)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.17400 \u001b[0m(+0.00475)\n",
            "     | > avg_loss_disc:\u001b[91m 3.56243 \u001b[0m(+0.18460)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.12282 \u001b[0m(-0.07041)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.15576 \u001b[0m(+0.11085)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.09164 \u001b[0m(-0.09927)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.15760 \u001b[0m(+0.04718)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.08991 \u001b[0m(-0.17788)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.13172 \u001b[0m(-0.09148)\n",
            "     | > avg_loss_0:\u001b[91m 3.56243 \u001b[0m(+0.18460)\n",
            "     | > avg_loss_gen:\u001b[92m 0.75806 \u001b[0m(-0.30472)\n",
            "     | > avg_loss_kl:\u001b[92m 179.26276 \u001b[0m(-3.31796)\n",
            "     | > avg_loss_feat:\u001b[92m 0.11959 \u001b[0m(-0.46438)\n",
            "     | > avg_loss_mel:\u001b[92m 72.24747 \u001b[0m(-0.36839)\n",
            "     | > avg_loss_duration:\u001b[91m 2.35861 \u001b[0m(+0.03216)\n",
            "     | > avg_loss_1:\u001b[92m 254.74648 \u001b[0m(-4.42329)\n",
            "\n",
            " > BEST MODEL : /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000/best_model_6.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 6/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:40:26) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.18215  (3.18215)\n",
            "     | > loss_disc_real_0: 0.12803  (0.12803)\n",
            "     | > loss_disc_real_1: 0.32229  (0.32229)\n",
            "     | > loss_disc_real_2: 0.18774  (0.18774)\n",
            "     | > loss_disc_real_3: 0.28729  (0.28729)\n",
            "     | > loss_disc_real_4: 0.15769  (0.15769)\n",
            "     | > loss_disc_real_5: 0.22642  (0.22642)\n",
            "     | > loss_0: 3.18215  (3.18215)\n",
            "     | > loss_gen: 1.34465  (1.34465)\n",
            "     | > loss_kl: 93.56258  (93.56258)\n",
            "     | > loss_feat: 0.39644  (0.39644)\n",
            "     | > loss_mel: 59.95653  (59.95653)\n",
            "     | > loss_duration: 2.81008  (2.81008)\n",
            "     | > loss_1: 158.07030  (158.07030)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.15863 \u001b[0m(-0.01538)\n",
            "     | > avg_loss_disc:\u001b[92m 3.18215 \u001b[0m(-0.38028)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.12803 \u001b[0m(+0.00521)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.32229 \u001b[0m(+0.16653)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.18774 \u001b[0m(+0.09610)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.28729 \u001b[0m(+0.12969)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.15769 \u001b[0m(+0.06778)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.22642 \u001b[0m(+0.09470)\n",
            "     | > avg_loss_0:\u001b[92m 3.18215 \u001b[0m(-0.38028)\n",
            "     | > avg_loss_gen:\u001b[91m 1.34465 \u001b[0m(+0.58660)\n",
            "     | > avg_loss_kl:\u001b[92m 93.56258 \u001b[0m(-85.70017)\n",
            "     | > avg_loss_feat:\u001b[91m 0.39644 \u001b[0m(+0.27685)\n",
            "     | > avg_loss_mel:\u001b[92m 59.95653 \u001b[0m(-12.29094)\n",
            "     | > avg_loss_duration:\u001b[91m 2.81008 \u001b[0m(+0.45148)\n",
            "     | > avg_loss_1:\u001b[92m 158.07030 \u001b[0m(-96.67618)\n",
            "\n",
            " > BEST MODEL : /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000/best_model_7.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 7/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:40:38) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.17082  (3.17082)\n",
            "     | > loss_disc_real_0: 0.17058  (0.17058)\n",
            "     | > loss_disc_real_1: 0.42690  (0.42690)\n",
            "     | > loss_disc_real_2: 0.32752  (0.32752)\n",
            "     | > loss_disc_real_3: 0.38376  (0.38376)\n",
            "     | > loss_disc_real_4: 0.30065  (0.30065)\n",
            "     | > loss_disc_real_5: 0.35557  (0.35557)\n",
            "     | > loss_0: 3.17082  (3.17082)\n",
            "     | > loss_gen: 1.99087  (1.99087)\n",
            "     | > loss_kl: 57.40475  (57.40475)\n",
            "     | > loss_feat: 0.28632  (0.28632)\n",
            "     | > loss_mel: 66.03524  (66.03524)\n",
            "     | > loss_duration: 2.45764  (2.45764)\n",
            "     | > loss_1: 128.17482  (128.17482)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.17174 \u001b[0m(+0.01311)\n",
            "     | > avg_loss_disc:\u001b[92m 3.17082 \u001b[0m(-0.01133)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.17058 \u001b[0m(+0.04255)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.42690 \u001b[0m(+0.10461)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.32752 \u001b[0m(+0.13978)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.38376 \u001b[0m(+0.09648)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.30065 \u001b[0m(+0.14296)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.35557 \u001b[0m(+0.12915)\n",
            "     | > avg_loss_0:\u001b[92m 3.17082 \u001b[0m(-0.01133)\n",
            "     | > avg_loss_gen:\u001b[91m 1.99087 \u001b[0m(+0.64622)\n",
            "     | > avg_loss_kl:\u001b[92m 57.40475 \u001b[0m(-36.15783)\n",
            "     | > avg_loss_feat:\u001b[92m 0.28632 \u001b[0m(-0.11012)\n",
            "     | > avg_loss_mel:\u001b[91m 66.03524 \u001b[0m(+6.07871)\n",
            "     | > avg_loss_duration:\u001b[92m 2.45764 \u001b[0m(-0.35245)\n",
            "     | > avg_loss_1:\u001b[92m 128.17482 \u001b[0m(-29.89548)\n",
            "\n",
            " > BEST MODEL : /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000/best_model_8.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 8/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:40:50) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.25081  (3.25081)\n",
            "     | > loss_disc_real_0: 0.23204  (0.23204)\n",
            "     | > loss_disc_real_1: 0.43907  (0.43907)\n",
            "     | > loss_disc_real_2: 0.40586  (0.40586)\n",
            "     | > loss_disc_real_3: 0.40222  (0.40222)\n",
            "     | > loss_disc_real_4: 0.41030  (0.41030)\n",
            "     | > loss_disc_real_5: 0.42503  (0.42503)\n",
            "     | > loss_0: 3.25081  (3.25081)\n",
            "     | > loss_gen: 2.32069  (2.32069)\n",
            "     | > loss_kl: 43.39094  (43.39094)\n",
            "     | > loss_feat: 0.05458  (0.05458)\n",
            "     | > loss_mel: 86.37434  (86.37434)\n",
            "     | > loss_duration: 2.58267  (2.58267)\n",
            "     | > loss_1: 134.72322  (134.72322)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17163 \u001b[0m(-0.00011)\n",
            "     | > avg_loss_disc:\u001b[91m 3.25081 \u001b[0m(+0.07998)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.23204 \u001b[0m(+0.06147)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.43907 \u001b[0m(+0.01217)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.40586 \u001b[0m(+0.07835)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.40222 \u001b[0m(+0.01846)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.41030 \u001b[0m(+0.10965)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.42503 \u001b[0m(+0.06946)\n",
            "     | > avg_loss_0:\u001b[91m 3.25081 \u001b[0m(+0.07998)\n",
            "     | > avg_loss_gen:\u001b[91m 2.32069 \u001b[0m(+0.32982)\n",
            "     | > avg_loss_kl:\u001b[92m 43.39094 \u001b[0m(-14.01381)\n",
            "     | > avg_loss_feat:\u001b[92m 0.05458 \u001b[0m(-0.23174)\n",
            "     | > avg_loss_mel:\u001b[91m 86.37434 \u001b[0m(+20.33910)\n",
            "     | > avg_loss_duration:\u001b[91m 2.58267 \u001b[0m(+0.12504)\n",
            "     | > avg_loss_1:\u001b[91m 134.72322 \u001b[0m(+6.54840)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 9/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:40:55) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.21527  (3.21527)\n",
            "     | > loss_disc_real_0: 0.28876  (0.28876)\n",
            "     | > loss_disc_real_1: 0.38216  (0.38216)\n",
            "     | > loss_disc_real_2: 0.39728  (0.39728)\n",
            "     | > loss_disc_real_3: 0.35968  (0.35968)\n",
            "     | > loss_disc_real_4: 0.44205  (0.44205)\n",
            "     | > loss_disc_real_5: 0.41641  (0.41641)\n",
            "     | > loss_0: 3.21527  (3.21527)\n",
            "     | > loss_gen: 2.29455  (2.29455)\n",
            "     | > loss_kl: 34.50960  (34.50960)\n",
            "     | > loss_feat: 0.15947  (0.15947)\n",
            "     | > loss_mel: 56.12580  (56.12580)\n",
            "     | > loss_duration: 2.44111  (2.44111)\n",
            "     | > loss_1: 95.53053  (95.53053)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.16998 \u001b[0m(-0.00164)\n",
            "     | > avg_loss_disc:\u001b[92m 3.21527 \u001b[0m(-0.03554)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.28876 \u001b[0m(+0.05672)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.38216 \u001b[0m(-0.05691)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.39728 \u001b[0m(-0.00859)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.35968 \u001b[0m(-0.04254)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.44205 \u001b[0m(+0.03175)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.41641 \u001b[0m(-0.00862)\n",
            "     | > avg_loss_0:\u001b[92m 3.21527 \u001b[0m(-0.03554)\n",
            "     | > avg_loss_gen:\u001b[92m 2.29455 \u001b[0m(-0.02614)\n",
            "     | > avg_loss_kl:\u001b[92m 34.50960 \u001b[0m(-8.88134)\n",
            "     | > avg_loss_feat:\u001b[91m 0.15947 \u001b[0m(+0.10489)\n",
            "     | > avg_loss_mel:\u001b[92m 56.12580 \u001b[0m(-30.24854)\n",
            "     | > avg_loss_duration:\u001b[92m 2.44111 \u001b[0m(-0.14156)\n",
            "     | > avg_loss_1:\u001b[92m 95.53053 \u001b[0m(-39.19270)\n",
            "\n",
            " > BEST MODEL : /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000/best_model_10.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 10/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:41:07) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.06353  (3.06353)\n",
            "     | > loss_disc_real_0: 0.32780  (0.32780)\n",
            "     | > loss_disc_real_1: 0.27417  (0.27417)\n",
            "     | > loss_disc_real_2: 0.31553  (0.31553)\n",
            "     | > loss_disc_real_3: 0.28069  (0.28069)\n",
            "     | > loss_disc_real_4: 0.39806  (0.39806)\n",
            "     | > loss_disc_real_5: 0.35169  (0.35169)\n",
            "     | > loss_0: 3.06353  (3.06353)\n",
            "     | > loss_gen: 2.02747  (2.02747)\n",
            "     | > loss_kl: 27.48511  (27.48511)\n",
            "     | > loss_feat: 0.70091  (0.70091)\n",
            "     | > loss_mel: 49.40341  (49.40341)\n",
            "     | > loss_duration: 2.38873  (2.38873)\n",
            "     | > loss_1: 82.00563  (82.00563)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18721 \u001b[0m(+0.01723)\n",
            "     | > avg_loss_disc:\u001b[92m 3.06353 \u001b[0m(-0.15174)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.32780 \u001b[0m(+0.03904)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.27417 \u001b[0m(-0.10800)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.31553 \u001b[0m(-0.08175)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.28069 \u001b[0m(-0.07899)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.39806 \u001b[0m(-0.04398)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.35169 \u001b[0m(-0.06472)\n",
            "     | > avg_loss_0:\u001b[92m 3.06353 \u001b[0m(-0.15174)\n",
            "     | > avg_loss_gen:\u001b[92m 2.02747 \u001b[0m(-0.26707)\n",
            "     | > avg_loss_kl:\u001b[92m 27.48511 \u001b[0m(-7.02449)\n",
            "     | > avg_loss_feat:\u001b[91m 0.70091 \u001b[0m(+0.54145)\n",
            "     | > avg_loss_mel:\u001b[92m 49.40341 \u001b[0m(-6.72239)\n",
            "     | > avg_loss_duration:\u001b[92m 2.38873 \u001b[0m(-0.05238)\n",
            "     | > avg_loss_1:\u001b[92m 82.00563 \u001b[0m(-13.52489)\n",
            "\n",
            " > BEST MODEL : /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000/best_model_11.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 11/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:41:20) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.11228  (3.11228)\n",
            "     | > loss_disc_real_0: 0.34677  (0.34677)\n",
            "     | > loss_disc_real_1: 0.20830  (0.20830)\n",
            "     | > loss_disc_real_2: 0.25601  (0.25601)\n",
            "     | > loss_disc_real_3: 0.22226  (0.22226)\n",
            "     | > loss_disc_real_4: 0.34936  (0.34936)\n",
            "     | > loss_disc_real_5: 0.27916  (0.27916)\n",
            "     | > loss_0: 3.11228  (3.11228)\n",
            "     | > loss_gen: 1.66444  (1.66444)\n",
            "     | > loss_kl: 21.10659  (21.10659)\n",
            "     | > loss_feat: 0.05790  (0.05790)\n",
            "     | > loss_mel: 51.36927  (51.36927)\n",
            "     | > loss_duration: 2.53629  (2.53629)\n",
            "     | > loss_1: 76.73449  (76.73449)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.16339 \u001b[0m(-0.02383)\n",
            "     | > avg_loss_disc:\u001b[91m 3.11228 \u001b[0m(+0.04875)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.34677 \u001b[0m(+0.01897)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.20830 \u001b[0m(-0.06586)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.25601 \u001b[0m(-0.05952)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.22226 \u001b[0m(-0.05843)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.34936 \u001b[0m(-0.04870)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.27916 \u001b[0m(-0.07253)\n",
            "     | > avg_loss_0:\u001b[91m 3.11228 \u001b[0m(+0.04875)\n",
            "     | > avg_loss_gen:\u001b[92m 1.66444 \u001b[0m(-0.36303)\n",
            "     | > avg_loss_kl:\u001b[92m 21.10659 \u001b[0m(-6.37852)\n",
            "     | > avg_loss_feat:\u001b[92m 0.05790 \u001b[0m(-0.64301)\n",
            "     | > avg_loss_mel:\u001b[91m 51.36927 \u001b[0m(+1.96586)\n",
            "     | > avg_loss_duration:\u001b[91m 2.53629 \u001b[0m(+0.14756)\n",
            "     | > avg_loss_1:\u001b[92m 76.73449 \u001b[0m(-5.27114)\n",
            "\n",
            " > BEST MODEL : /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000/best_model_12.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 12/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:41:32) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.07627  (3.07627)\n",
            "     | > loss_disc_real_0: 0.34215  (0.34215)\n",
            "     | > loss_disc_real_1: 0.16350  (0.16350)\n",
            "     | > loss_disc_real_2: 0.18427  (0.18427)\n",
            "     | > loss_disc_real_3: 0.20122  (0.20122)\n",
            "     | > loss_disc_real_4: 0.25700  (0.25700)\n",
            "     | > loss_disc_real_5: 0.21014  (0.21014)\n",
            "     | > loss_0: 3.07627  (3.07627)\n",
            "     | > loss_gen: 1.42022  (1.42022)\n",
            "     | > loss_kl: 16.56146  (16.56146)\n",
            "     | > loss_feat: 0.55119  (0.55119)\n",
            "     | > loss_mel: 70.95147  (70.95147)\n",
            "     | > loss_duration: 2.77834  (2.77834)\n",
            "     | > loss_1: 92.26268  (92.26268)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.20958 \u001b[0m(+0.04620)\n",
            "     | > avg_loss_disc:\u001b[92m 3.07627 \u001b[0m(-0.03600)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.34215 \u001b[0m(-0.00462)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.16350 \u001b[0m(-0.04480)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.18427 \u001b[0m(-0.07173)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.20122 \u001b[0m(-0.02104)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.25700 \u001b[0m(-0.09236)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.21014 \u001b[0m(-0.06902)\n",
            "     | > avg_loss_0:\u001b[92m 3.07627 \u001b[0m(-0.03600)\n",
            "     | > avg_loss_gen:\u001b[92m 1.42022 \u001b[0m(-0.24422)\n",
            "     | > avg_loss_kl:\u001b[92m 16.56146 \u001b[0m(-4.54513)\n",
            "     | > avg_loss_feat:\u001b[91m 0.55119 \u001b[0m(+0.49329)\n",
            "     | > avg_loss_mel:\u001b[91m 70.95147 \u001b[0m(+19.58220)\n",
            "     | > avg_loss_duration:\u001b[91m 2.77834 \u001b[0m(+0.24205)\n",
            "     | > avg_loss_1:\u001b[91m 92.26268 \u001b[0m(+15.52819)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 13/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:41:37) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.11674  (3.11674)\n",
            "     | > loss_disc_real_0: 0.32313  (0.32313)\n",
            "     | > loss_disc_real_1: 0.20436  (0.20436)\n",
            "     | > loss_disc_real_2: 0.20081  (0.20081)\n",
            "     | > loss_disc_real_3: 0.24185  (0.24185)\n",
            "     | > loss_disc_real_4: 0.20929  (0.20929)\n",
            "     | > loss_disc_real_5: 0.22191  (0.22191)\n",
            "     | > loss_0: 3.11674  (3.11674)\n",
            "     | > loss_gen: 1.40716  (1.40716)\n",
            "     | > loss_kl: 13.85727  (13.85727)\n",
            "     | > loss_feat: 0.04687  (0.04687)\n",
            "     | > loss_mel: 73.04552  (73.04552)\n",
            "     | > loss_duration: 2.83524  (2.83524)\n",
            "     | > loss_1: 91.19204  (91.19204)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18051 \u001b[0m(-0.02908)\n",
            "     | > avg_loss_disc:\u001b[91m 3.11674 \u001b[0m(+0.04047)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.32313 \u001b[0m(-0.01902)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.20436 \u001b[0m(+0.04086)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.20081 \u001b[0m(+0.01654)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.24185 \u001b[0m(+0.04063)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.20929 \u001b[0m(-0.04772)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.22191 \u001b[0m(+0.01177)\n",
            "     | > avg_loss_0:\u001b[91m 3.11674 \u001b[0m(+0.04047)\n",
            "     | > avg_loss_gen:\u001b[92m 1.40716 \u001b[0m(-0.01306)\n",
            "     | > avg_loss_kl:\u001b[92m 13.85727 \u001b[0m(-2.70419)\n",
            "     | > avg_loss_feat:\u001b[92m 0.04687 \u001b[0m(-0.50432)\n",
            "     | > avg_loss_mel:\u001b[91m 73.04552 \u001b[0m(+2.09405)\n",
            "     | > avg_loss_duration:\u001b[91m 2.83524 \u001b[0m(+0.05690)\n",
            "     | > avg_loss_1:\u001b[92m 91.19204 \u001b[0m(-1.07064)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 14/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:41:41) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.02478  (3.02478)\n",
            "     | > loss_disc_real_0: 0.29320  (0.29320)\n",
            "     | > loss_disc_real_1: 0.24380  (0.24380)\n",
            "     | > loss_disc_real_2: 0.22762  (0.22762)\n",
            "     | > loss_disc_real_3: 0.27906  (0.27906)\n",
            "     | > loss_disc_real_4: 0.19670  (0.19670)\n",
            "     | > loss_disc_real_5: 0.25095  (0.25095)\n",
            "     | > loss_0: 3.02478  (3.02478)\n",
            "     | > loss_gen: 1.55774  (1.55774)\n",
            "     | > loss_kl: 11.07804  (11.07804)\n",
            "     | > loss_feat: 0.46907  (0.46907)\n",
            "     | > loss_mel: 64.22287  (64.22287)\n",
            "     | > loss_duration: 2.50452  (2.50452)\n",
            "     | > loss_1: 79.83225  (79.83225)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18171 \u001b[0m(+0.00121)\n",
            "     | > avg_loss_disc:\u001b[92m 3.02478 \u001b[0m(-0.09196)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.29320 \u001b[0m(-0.02993)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.24380 \u001b[0m(+0.03944)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.22762 \u001b[0m(+0.02681)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.27906 \u001b[0m(+0.03721)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.19670 \u001b[0m(-0.01258)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.25095 \u001b[0m(+0.02904)\n",
            "     | > avg_loss_0:\u001b[92m 3.02478 \u001b[0m(-0.09196)\n",
            "     | > avg_loss_gen:\u001b[91m 1.55774 \u001b[0m(+0.15058)\n",
            "     | > avg_loss_kl:\u001b[92m 11.07804 \u001b[0m(-2.77922)\n",
            "     | > avg_loss_feat:\u001b[91m 0.46907 \u001b[0m(+0.42221)\n",
            "     | > avg_loss_mel:\u001b[92m 64.22287 \u001b[0m(-8.82265)\n",
            "     | > avg_loss_duration:\u001b[92m 2.50452 \u001b[0m(-0.33071)\n",
            "     | > avg_loss_1:\u001b[92m 79.83225 \u001b[0m(-11.35979)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 15/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:41:46) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.01625  (3.01625)\n",
            "     | > loss_disc_real_0: 0.26342  (0.26342)\n",
            "     | > loss_disc_real_1: 0.28714  (0.28714)\n",
            "     | > loss_disc_real_2: 0.27501  (0.27501)\n",
            "     | > loss_disc_real_3: 0.30524  (0.30524)\n",
            "     | > loss_disc_real_4: 0.23697  (0.23697)\n",
            "     | > loss_disc_real_5: 0.29798  (0.29798)\n",
            "     | > loss_0: 3.01625  (3.01625)\n",
            "     | > loss_gen: 1.73418  (1.73418)\n",
            "     | > loss_kl: 9.44989  (9.44989)\n",
            "     | > loss_feat: 0.43097  (0.43097)\n",
            "     | > loss_mel: 62.54362  (62.54362)\n",
            "     | > loss_duration: 2.79925  (2.79925)\n",
            "     | > loss_1: 76.95790  (76.95790)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17968 \u001b[0m(-0.00204)\n",
            "     | > avg_loss_disc:\u001b[92m 3.01625 \u001b[0m(-0.00854)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.26342 \u001b[0m(-0.02978)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.28714 \u001b[0m(+0.04334)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.27501 \u001b[0m(+0.04739)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.30524 \u001b[0m(+0.02618)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.23697 \u001b[0m(+0.04027)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.29798 \u001b[0m(+0.04703)\n",
            "     | > avg_loss_0:\u001b[92m 3.01625 \u001b[0m(-0.00854)\n",
            "     | > avg_loss_gen:\u001b[91m 1.73418 \u001b[0m(+0.17644)\n",
            "     | > avg_loss_kl:\u001b[92m 9.44989 \u001b[0m(-1.62816)\n",
            "     | > avg_loss_feat:\u001b[92m 0.43097 \u001b[0m(-0.03810)\n",
            "     | > avg_loss_mel:\u001b[92m 62.54362 \u001b[0m(-1.67925)\n",
            "     | > avg_loss_duration:\u001b[91m 2.79925 \u001b[0m(+0.29473)\n",
            "     | > avg_loss_1:\u001b[92m 76.95790 \u001b[0m(-2.87435)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 16/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:41:51) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.02720  (3.02720)\n",
            "     | > loss_disc_real_0: 0.23923  (0.23923)\n",
            "     | > loss_disc_real_1: 0.30452  (0.30452)\n",
            "     | > loss_disc_real_2: 0.29928  (0.29928)\n",
            "     | > loss_disc_real_3: 0.30642  (0.30642)\n",
            "     | > loss_disc_real_4: 0.28641  (0.28641)\n",
            "     | > loss_disc_real_5: 0.31689  (0.31689)\n",
            "     | > loss_0: 3.02720  (3.02720)\n",
            "     | > loss_gen: 1.81692  (1.81692)\n",
            "     | > loss_kl: 8.38699  (8.38699)\n",
            "     | > loss_feat: 0.35985  (0.35985)\n",
            "     | > loss_mel: 58.13793  (58.13793)\n",
            "     | > loss_duration: 2.63559  (2.63559)\n",
            "     | > loss_1: 71.33727  (71.33727)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18051 \u001b[0m(+0.00084)\n",
            "     | > avg_loss_disc:\u001b[91m 3.02720 \u001b[0m(+0.01096)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.23923 \u001b[0m(-0.02419)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.30452 \u001b[0m(+0.01739)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.29928 \u001b[0m(+0.02426)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.30642 \u001b[0m(+0.00119)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.28641 \u001b[0m(+0.04944)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.31689 \u001b[0m(+0.01891)\n",
            "     | > avg_loss_0:\u001b[91m 3.02720 \u001b[0m(+0.01096)\n",
            "     | > avg_loss_gen:\u001b[91m 1.81692 \u001b[0m(+0.08274)\n",
            "     | > avg_loss_kl:\u001b[92m 8.38699 \u001b[0m(-1.06289)\n",
            "     | > avg_loss_feat:\u001b[92m 0.35985 \u001b[0m(-0.07112)\n",
            "     | > avg_loss_mel:\u001b[92m 58.13793 \u001b[0m(-4.40569)\n",
            "     | > avg_loss_duration:\u001b[92m 2.63559 \u001b[0m(-0.16367)\n",
            "     | > avg_loss_1:\u001b[92m 71.33727 \u001b[0m(-5.62063)\n",
            "\n",
            " > BEST MODEL : /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000/best_model_17.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 17/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:42:03) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.08562  (3.08562)\n",
            "     | > loss_disc_real_0: 0.22607  (0.22607)\n",
            "     | > loss_disc_real_1: 0.29854  (0.29854)\n",
            "     | > loss_disc_real_2: 0.30376  (0.30376)\n",
            "     | > loss_disc_real_3: 0.28461  (0.28461)\n",
            "     | > loss_disc_real_4: 0.32711  (0.32711)\n",
            "     | > loss_disc_real_5: 0.31260  (0.31260)\n",
            "     | > loss_0: 3.08562  (3.08562)\n",
            "     | > loss_gen: 1.75027  (1.75027)\n",
            "     | > loss_kl: 6.55017  (6.55017)\n",
            "     | > loss_feat: 0.02848  (0.02848)\n",
            "     | > loss_mel: 50.49068  (50.49068)\n",
            "     | > loss_duration: 2.54563  (2.54563)\n",
            "     | > loss_1: 61.36522  (61.36522)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18110 \u001b[0m(+0.00059)\n",
            "     | > avg_loss_disc:\u001b[91m 3.08562 \u001b[0m(+0.05842)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.22607 \u001b[0m(-0.01317)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.29854 \u001b[0m(-0.00598)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.30376 \u001b[0m(+0.00449)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.28461 \u001b[0m(-0.02182)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.32711 \u001b[0m(+0.04070)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.31260 \u001b[0m(-0.00428)\n",
            "     | > avg_loss_0:\u001b[91m 3.08562 \u001b[0m(+0.05842)\n",
            "     | > avg_loss_gen:\u001b[92m 1.75027 \u001b[0m(-0.06665)\n",
            "     | > avg_loss_kl:\u001b[92m 6.55017 \u001b[0m(-1.83682)\n",
            "     | > avg_loss_feat:\u001b[92m 0.02848 \u001b[0m(-0.33138)\n",
            "     | > avg_loss_mel:\u001b[92m 50.49068 \u001b[0m(-7.64725)\n",
            "     | > avg_loss_duration:\u001b[92m 2.54563 \u001b[0m(-0.08996)\n",
            "     | > avg_loss_1:\u001b[92m 61.36522 \u001b[0m(-9.97205)\n",
            "\n",
            " > BEST MODEL : /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000/best_model_18.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 18/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:42:16) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.04872  (3.04872)\n",
            "     | > loss_disc_real_0: 0.22395  (0.22395)\n",
            "     | > loss_disc_real_1: 0.24905  (0.24905)\n",
            "     | > loss_disc_real_2: 0.25551  (0.25551)\n",
            "     | > loss_disc_real_3: 0.24630  (0.24630)\n",
            "     | > loss_disc_real_4: 0.32250  (0.32250)\n",
            "     | > loss_disc_real_5: 0.26895  (0.26895)\n",
            "     | > loss_0: 3.04872  (3.04872)\n",
            "     | > loss_gen: 1.59099  (1.59099)\n",
            "     | > loss_kl: 4.96280  (4.96280)\n",
            "     | > loss_feat: 0.16821  (0.16821)\n",
            "     | > loss_mel: 48.07754  (48.07754)\n",
            "     | > loss_duration: 2.45798  (2.45798)\n",
            "     | > loss_1: 57.25752  (57.25752)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.16905 \u001b[0m(-0.01205)\n",
            "     | > avg_loss_disc:\u001b[92m 3.04872 \u001b[0m(-0.03690)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.22395 \u001b[0m(-0.00212)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.24905 \u001b[0m(-0.04949)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.25551 \u001b[0m(-0.04825)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.24630 \u001b[0m(-0.03831)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.32250 \u001b[0m(-0.00461)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.26895 \u001b[0m(-0.04366)\n",
            "     | > avg_loss_0:\u001b[92m 3.04872 \u001b[0m(-0.03690)\n",
            "     | > avg_loss_gen:\u001b[92m 1.59099 \u001b[0m(-0.15927)\n",
            "     | > avg_loss_kl:\u001b[92m 4.96280 \u001b[0m(-1.58737)\n",
            "     | > avg_loss_feat:\u001b[91m 0.16821 \u001b[0m(+0.13973)\n",
            "     | > avg_loss_mel:\u001b[92m 48.07754 \u001b[0m(-2.41314)\n",
            "     | > avg_loss_duration:\u001b[92m 2.45798 \u001b[0m(-0.08765)\n",
            "     | > avg_loss_1:\u001b[92m 57.25752 \u001b[0m(-4.10770)\n",
            "\n",
            " > BEST MODEL : /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000/best_model_19.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 19/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:42:28) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.95280  (2.95280)\n",
            "     | > loss_disc_real_0: 0.23145  (0.23145)\n",
            "     | > loss_disc_real_1: 0.20616  (0.20616)\n",
            "     | > loss_disc_real_2: 0.20711  (0.20711)\n",
            "     | > loss_disc_real_3: 0.23006  (0.23006)\n",
            "     | > loss_disc_real_4: 0.27965  (0.27965)\n",
            "     | > loss_disc_real_5: 0.22816  (0.22816)\n",
            "     | > loss_0: 2.95280  (2.95280)\n",
            "     | > loss_gen: 1.50037  (1.50037)\n",
            "     | > loss_kl: 5.00636  (5.00636)\n",
            "     | > loss_feat: 0.57779  (0.57779)\n",
            "     | > loss_mel: 55.46651  (55.46651)\n",
            "     | > loss_duration: 2.45948  (2.45948)\n",
            "     | > loss_1: 65.01051  (65.01051)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.17995 \u001b[0m(+0.01090)\n",
            "     | > avg_loss_disc:\u001b[92m 2.95280 \u001b[0m(-0.09592)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.23145 \u001b[0m(+0.00751)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.20616 \u001b[0m(-0.04289)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.20711 \u001b[0m(-0.04840)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.23006 \u001b[0m(-0.01624)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.27965 \u001b[0m(-0.04284)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.22816 \u001b[0m(-0.04079)\n",
            "     | > avg_loss_0:\u001b[92m 2.95280 \u001b[0m(-0.09592)\n",
            "     | > avg_loss_gen:\u001b[92m 1.50037 \u001b[0m(-0.09063)\n",
            "     | > avg_loss_kl:\u001b[91m 5.00636 \u001b[0m(+0.04357)\n",
            "     | > avg_loss_feat:\u001b[91m 0.57779 \u001b[0m(+0.40959)\n",
            "     | > avg_loss_mel:\u001b[91m 55.46651 \u001b[0m(+7.38897)\n",
            "     | > avg_loss_duration:\u001b[91m 2.45948 \u001b[0m(+0.00150)\n",
            "     | > avg_loss_1:\u001b[91m 65.01051 \u001b[0m(+7.75299)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 20/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:42:33) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.06476  (3.06476)\n",
            "     | > loss_disc_real_0: 0.24703  (0.24703)\n",
            "     | > loss_disc_real_1: 0.25110  (0.25110)\n",
            "     | > loss_disc_real_2: 0.25651  (0.25651)\n",
            "     | > loss_disc_real_3: 0.26641  (0.26641)\n",
            "     | > loss_disc_real_4: 0.26795  (0.26795)\n",
            "     | > loss_disc_real_5: 0.25952  (0.25952)\n",
            "     | > loss_0: 3.06476  (3.06476)\n",
            "     | > loss_gen: 1.54494  (1.54494)\n",
            "     | > loss_kl: 4.52470  (4.52470)\n",
            "     | > loss_feat: 0.03579  (0.03579)\n",
            "     | > loss_mel: 66.99288  (66.99288)\n",
            "     | > loss_duration: 2.56327  (2.56327)\n",
            "     | > loss_1: 75.66159  (75.66159)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18671 \u001b[0m(+0.00677)\n",
            "     | > avg_loss_disc:\u001b[91m 3.06476 \u001b[0m(+0.11196)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.24703 \u001b[0m(+0.01558)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.25110 \u001b[0m(+0.04495)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.25651 \u001b[0m(+0.04939)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.26641 \u001b[0m(+0.03635)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.26795 \u001b[0m(-0.01170)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.25952 \u001b[0m(+0.03136)\n",
            "     | > avg_loss_0:\u001b[91m 3.06476 \u001b[0m(+0.11196)\n",
            "     | > avg_loss_gen:\u001b[91m 1.54494 \u001b[0m(+0.04457)\n",
            "     | > avg_loss_kl:\u001b[92m 4.52470 \u001b[0m(-0.48166)\n",
            "     | > avg_loss_feat:\u001b[92m 0.03579 \u001b[0m(-0.54200)\n",
            "     | > avg_loss_mel:\u001b[91m 66.99288 \u001b[0m(+11.52637)\n",
            "     | > avg_loss_duration:\u001b[91m 2.56327 \u001b[0m(+0.10379)\n",
            "     | > avg_loss_1:\u001b[91m 75.66159 \u001b[0m(+10.65108)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 21/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:42:38) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.06170  (3.06170)\n",
            "     | > loss_disc_real_0: 0.26273  (0.26273)\n",
            "     | > loss_disc_real_1: 0.27510  (0.27510)\n",
            "     | > loss_disc_real_2: 0.28110  (0.28110)\n",
            "     | > loss_disc_real_3: 0.28601  (0.28601)\n",
            "     | > loss_disc_real_4: 0.25157  (0.25157)\n",
            "     | > loss_disc_real_5: 0.28088  (0.28088)\n",
            "     | > loss_0: 3.06170  (3.06170)\n",
            "     | > loss_gen: 1.63602  (1.63602)\n",
            "     | > loss_kl: 4.97673  (4.97673)\n",
            "     | > loss_feat: 0.02993  (0.02993)\n",
            "     | > loss_mel: 71.40386  (71.40386)\n",
            "     | > loss_duration: 2.49550  (2.49550)\n",
            "     | > loss_1: 80.54205  (80.54205)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18407 \u001b[0m(-0.00265)\n",
            "     | > avg_loss_disc:\u001b[92m 3.06170 \u001b[0m(-0.00306)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.26273 \u001b[0m(+0.01570)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.27510 \u001b[0m(+0.02400)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.28110 \u001b[0m(+0.02459)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.28601 \u001b[0m(+0.01960)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.25157 \u001b[0m(-0.01638)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.28088 \u001b[0m(+0.02136)\n",
            "     | > avg_loss_0:\u001b[92m 3.06170 \u001b[0m(-0.00306)\n",
            "     | > avg_loss_gen:\u001b[91m 1.63602 \u001b[0m(+0.09108)\n",
            "     | > avg_loss_kl:\u001b[91m 4.97673 \u001b[0m(+0.45202)\n",
            "     | > avg_loss_feat:\u001b[92m 0.02993 \u001b[0m(-0.00586)\n",
            "     | > avg_loss_mel:\u001b[91m 71.40386 \u001b[0m(+4.41098)\n",
            "     | > avg_loss_duration:\u001b[92m 2.49550 \u001b[0m(-0.06777)\n",
            "     | > avg_loss_1:\u001b[91m 80.54205 \u001b[0m(+4.88046)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 22/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:42:42) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.04664  (3.04664)\n",
            "     | > loss_disc_real_0: 0.27483  (0.27483)\n",
            "     | > loss_disc_real_1: 0.28093  (0.28093)\n",
            "     | > loss_disc_real_2: 0.29088  (0.29088)\n",
            "     | > loss_disc_real_3: 0.28595  (0.28595)\n",
            "     | > loss_disc_real_4: 0.25877  (0.25877)\n",
            "     | > loss_disc_real_5: 0.28568  (0.28568)\n",
            "     | > loss_0: 3.04664  (3.04664)\n",
            "     | > loss_gen: 1.69039  (1.69039)\n",
            "     | > loss_kl: 5.28554  (5.28554)\n",
            "     | > loss_feat: 0.09091  (0.09091)\n",
            "     | > loss_mel: 46.53247  (46.53247)\n",
            "     | > loss_duration: 2.44084  (2.44084)\n",
            "     | > loss_1: 56.04015  (56.04015)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17713 \u001b[0m(-0.00694)\n",
            "     | > avg_loss_disc:\u001b[92m 3.04664 \u001b[0m(-0.01506)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.27483 \u001b[0m(+0.01209)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.28093 \u001b[0m(+0.00583)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.29088 \u001b[0m(+0.00978)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.28595 \u001b[0m(-0.00006)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.25877 \u001b[0m(+0.00720)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.28568 \u001b[0m(+0.00480)\n",
            "     | > avg_loss_0:\u001b[92m 3.04664 \u001b[0m(-0.01506)\n",
            "     | > avg_loss_gen:\u001b[91m 1.69039 \u001b[0m(+0.05437)\n",
            "     | > avg_loss_kl:\u001b[91m 5.28554 \u001b[0m(+0.30881)\n",
            "     | > avg_loss_feat:\u001b[91m 0.09091 \u001b[0m(+0.06098)\n",
            "     | > avg_loss_mel:\u001b[92m 46.53247 \u001b[0m(-24.87139)\n",
            "     | > avg_loss_duration:\u001b[92m 2.44084 \u001b[0m(-0.05467)\n",
            "     | > avg_loss_1:\u001b[92m 56.04015 \u001b[0m(-24.50190)\n",
            "\n",
            " > BEST MODEL : /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000/best_model_23.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 23/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:42:55) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.78236  (2.78236)\n",
            "     | > loss_disc_real_0: 0.27837  (0.27837)\n",
            "     | > loss_disc_real_1: 0.21880  (0.21880)\n",
            "     | > loss_disc_real_2: 0.20757  (0.20757)\n",
            "     | > loss_disc_real_3: 0.23742  (0.23742)\n",
            "     | > loss_disc_real_4: 0.24143  (0.24143)\n",
            "     | > loss_disc_real_5: 0.22933  (0.22933)\n",
            "     | > loss_0: 2.78236  (2.78236)\n",
            "     | > loss_gen: 1.68639  (1.68639)\n",
            "     | > loss_kl: 5.85505  (5.85505)\n",
            "     | > loss_feat: 1.00654  (1.00654)\n",
            "     | > loss_mel: 56.76424  (56.76424)\n",
            "     | > loss_duration: 2.47659  (2.47659)\n",
            "     | > loss_1: 67.78880  (67.78880)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17170 \u001b[0m(-0.00543)\n",
            "     | > avg_loss_disc:\u001b[92m 2.78236 \u001b[0m(-0.26428)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.27837 \u001b[0m(+0.00355)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.21880 \u001b[0m(-0.06214)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.20757 \u001b[0m(-0.08331)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.23742 \u001b[0m(-0.04853)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.24143 \u001b[0m(-0.01733)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.22933 \u001b[0m(-0.05635)\n",
            "     | > avg_loss_0:\u001b[92m 2.78236 \u001b[0m(-0.26428)\n",
            "     | > avg_loss_gen:\u001b[92m 1.68639 \u001b[0m(-0.00400)\n",
            "     | > avg_loss_kl:\u001b[91m 5.85505 \u001b[0m(+0.56951)\n",
            "     | > avg_loss_feat:\u001b[91m 1.00654 \u001b[0m(+0.91563)\n",
            "     | > avg_loss_mel:\u001b[91m 56.76424 \u001b[0m(+10.23177)\n",
            "     | > avg_loss_duration:\u001b[91m 2.47659 \u001b[0m(+0.03575)\n",
            "     | > avg_loss_1:\u001b[91m 67.78880 \u001b[0m(+11.74865)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 24/100\u001b[0m\n",
            " --> /content/trainoutput/vits_ljspeech-December-10-2022_11+39PM-0000000\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2022-12-10 23:43:00) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 9\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 45\n",
            " | > Min text length: 37\n",
            " | > Avg text length: 42.111111111111114\n",
            " | \n",
            " | > Max audio length: 76839.0\n",
            " | > Min audio length: 56679.0\n",
            " | > Avg audio length: 66812.33333333333\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "\t| > 1 not found characters:\n",
            "\t| > ͡\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 39\n",
            " | > Avg text length: 39.0\n",
            " | \n",
            " | > Max audio length: 71079.0\n",
            " | > Min audio length: 71079.0\n",
            " | > Avg audio length: 71079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.50176  (2.50176)\n",
            "     | > loss_disc_real_0: 0.27252  (0.27252)\n",
            "     | > loss_disc_real_1: 0.14166  (0.14166)\n",
            "     | > loss_disc_real_2: 0.12528  (0.12528)\n",
            "     | > loss_disc_real_3: 0.19171  (0.19171)\n",
            "     | > loss_disc_real_4: 0.19698  (0.19698)\n",
            "     | > loss_disc_real_5: 0.16994  (0.16994)\n",
            "     | > loss_0: 2.50176  (2.50176)\n",
            "     | > loss_gen: 1.64867  (1.64867)\n",
            "     | > loss_kl: 5.75760  (5.75760)\n",
            "     | > loss_feat: 2.26076  (2.26076)\n",
            "     | > loss_mel: 49.87399  (49.87399)\n",
            "     | > loss_duration: 2.41536  (2.41536)\n",
            "     | > loss_1: 61.95639  (61.95639)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.19788 \u001b[0m(+0.02618)\n",
            "     | > avg_loss_disc:\u001b[92m 2.50176 \u001b[0m(-0.28060)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.27252 \u001b[0m(-0.00586)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.14166 \u001b[0m(-0.07713)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.12528 \u001b[0m(-0.08229)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.19171 \u001b[0m(-0.04571)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.19698 \u001b[0m(-0.04446)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.16994 \u001b[0m(-0.05939)\n",
            "     | > avg_loss_0:\u001b[92m 2.50176 \u001b[0m(-0.28060)\n",
            "     | > avg_loss_gen:\u001b[92m 1.64867 \u001b[0m(-0.03771)\n",
            "     | > avg_loss_kl:\u001b[92m 5.75760 \u001b[0m(-0.09745)\n",
            "     | > avg_loss_feat:\u001b[91m 2.26076 \u001b[0m(+1.25422)\n",
            "     | > avg_loss_mel:\u001b[92m 49.87399 \u001b[0m(-6.89025)\n",
            "     | > avg_loss_duration:\u001b[92m 2.41536 \u001b[0m(-0.06122)\n",
            "     | > avg_loss_1:\u001b[92m 61.95639 \u001b[0m(-5.83241)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## test it!"
      ],
      "metadata": {
        "id": "lrLe0m9ELwWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tts --text \"this is my new voice, lets see how it works. Maybe it does not sound like me.\" \\\n",
        "      --model_path 'trainoutput/output2/best_model_2.pth' \\\n",
        "      --config_path 'trainoutput/output2/config.json' \\\n",
        "      --out_path 'trainoutput/output2/out.wav'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88nFU7l8Wpdt",
        "outputId": "cfe1303a-00f3-4164-d58f-6f82d7f7b974"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Using model: vits\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:0\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:None\n",
            " | > fft_size:1024\n",
            " | > power:None\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:None\n",
            " | > signal_norm:None\n",
            " | > symmetric_norm:None\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:None\n",
            " | > pitch_fmax:None\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:1.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Text: this is my new voice, lets see how it works. Maybe it does not sound like me.\n",
            " > Text splitted to sentences.\n",
            "['this is my new voice, lets see how it works.', 'Maybe it does not sound like me.']\n",
            " > Processing time: 4.919254779815674\n",
            " > Real-time factor: 1.2312655273217354\n",
            " > Saving output to trainoutput/output2/out.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPqSkGyoXSQg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}